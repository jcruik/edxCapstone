---
title: "edX MovieLens Project"
author: "James Cruikshanks"
date: "7/17/2021"
output: pdf_document
---

```{r setup, include=FALSE}
load("~/R/edxCapstone/recommender.RData") #make sure to save the workspace image before running RMD.

#Replace with entire script before submission
library(tidyverse)
library(lubridate)
library(knitr)
```

## Introduction

Using a large database of movie ratings, this project builds a machine learning model that predicts how a user will rate a given movie. The dataset includes 10 million ratings of more than 10,000 movies by over 72,000 users and can be downloaded from https://grouplens.org/datasets/movielens/10m/. Each rating contains 6 pieces of information: the user ID, the movie ID and title, the timestamp of the rating, and the genre(s) of the film. We can see the data structure by looking at the first few rows:

```{r raw data, echo=FALSE, warning=FALSE}
kable(head(edx))
```

Using the features present in the dataset, a model is created which is able to approximate and adjust for the effect of each one. How well each movie is liked by all users, how picky each user appears to be by their movie ratings, how well rated each genre appears to be, and even the week a movie was rated all present predictable patterns. These patterns are explored and exploited to predict how any user will rate any movie. The model performance is evaluated by the root mean square error between the predicted ratings and the actual ratings of a partitioned validation dataset, as determined by the following function:


```{r RMSE function, echo=TRUE}
RMSE <- function(actual_ratings, predicted_ratings){
  sqrt(mean((actual_ratings - predicted_ratings) ^ 2))
}
```

## Analysis

Firstly, the dataset is partitioned into a 'train' set and a 'test' set for various models to be tested while avoiding overfitting of the data to the validation set. `r nrow(train_set)` randomly selected ratings make up the training set and the remaining `r nrow(test_set)` ratings are used for model evaluation.

The prediction of a given user's rating of a given movie might be simply estimated by taking the average of all observed movie ratings. Expanding on this, we take the average of each movie's rating across all users, and each users rating across all movies. Called 'The User + Movie Effect Model', it is calculated as follows:

```{r user+movie effect model, echo=TRUE, message=FALSE, warning=FALSE}
#calculate the average rating across all movies and users
mean <- mean(train_set$rating)

#calculate and average user rating above or below the mean, per movie (the 'movie effect')
movie_avgs <- train_set %>%
  group_by(movieId) %>%
  summarize(movie_eff = mean(rating - mean))

#calculate average movie rating above or below the mean, per user (the 'user effect')
user_avgs <- train_set %>%
  left_join(movie_avgs, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(user_eff = mean(rating - mean - movie_eff))

#predict ratings using user and movie effects model
prediction <- test_set %>%
  left_join(movie_avgs, by = 'movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  mutate(pred = mean + user_eff + movie_eff) %>%
  .$pred
```

This model takes into account the effect of the movie, as well as the user. Using this model a RMSE of `r user_movie_RMSE` is achieved

Next, the average of all ratings in a given week is calculated across all of the given time stamps and plotted.

```{r date effect plot, echo=FALSE, message=FALSE, warning=FALSE}
date_plot +
  ylab("Mean Rating") +
  xlab("Week")
```

The plot shows a trend that can then be integrated into a new model called 'The User + Movie + Date Effect Model' as follows:
```{r date effect model, echo=TRUE, message=FALSE, warning=FALSE}
#approximate linear model to calculate the effect of date on user, movie rating
date_avgs <- train_set %>%
  left_join(movie_avgs, by = 'movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  
  #add column with week of rating
  mutate(date = as_datetime(timestamp), week = round_date(date, unit = "week")) %>%
  
  #calculate average movie rating above or below the mean for each user and movie, by week
  group_by(week) %>%
  summarize(date_eff = mean(rating-mean-user_eff-movie_eff))

##predict ratings using user, movie, and date effects model
#calculate week from test set timestamps
test_set_date <- test_set %>%
  mutate(week = round_date(as_datetime(timestamp), unit = "week"))

#calculate predicted rating
prediction <- test_set_date %>%
  left_join(movie_avgs, by = 'movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  left_join(date_avgs, by = 'week') %>%
  mutate(pred = mean + user_eff + movie_eff + date_eff) %>%
  .$pred
```

Using this model a RMSE of `r user_movie_date_RMSE` is achieved, a slight improvement.

Next, the average rating by genre is calculated and plotted with the standard error for genres with over 50000 ratings.

```{r genre effect plot, echo=FALSE, message=FALSE, warning=FALSE}
genre_plot +
  ylab("Mean Rating") +
  xlab("Genre")
```
## Results

presents the modeling results and discusses the model performance

## Conclusions

a brief summary of the report, its limitations and future work
