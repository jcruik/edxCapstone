---
title: "edX Vinho Verde Quality Prediction Project"
author: "James Cruikshanks"
date: "7/27/2021"
output: pdf_document
---

```{r setup, include=FALSE}
###Vinho Verde Quality Predictor
##Load required packages
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(caret)) install.packages("caret")
if(!require(rpart)) install.packages("rpart")
if(!require(randomForest)) install.packages("randomForest")
if(!require(knitr)) install.packages("knitr")
if(!require(kableExtra)) install.packages("kableExtra")

library(tidyverse)
library(caret)
library(rpart)
library(knitr)
library(kableExtra)

##Wrangle wine quality data
##data located here: http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip

#download zip file
dl <- tempfile()
download.file("http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip", dl)

#read csv files
reds <- read.csv(unzip(dl,"winequality/winequality-red.csv"), sep = ";")
whites <- read.csv(unzip(dl,"winequality/winequality-white.csv"), sep = ";")

#add categorical data
reds <- reds %>% mutate(colour = as.factor("red"))
whites <- whites %>% mutate(colour = as.factor("white"))

#merge data
wine_quality <- bind_rows(reds, whites)

#remove temp files
remove(dl, reds, whites)

#set the number of digits for rounding
options(digits = 5)

```
# Introduction

Using a public dataset and R scripts, this project attempts to create a model which would be useful to identify wine quality with a suite of chemical analyses. The dataset is available at the following URL: http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip. Exploratory data analysis reveals some useful insights about a few of the predictors and the subjective quality ratings themselves. The goal of the project is refined based on these insights, with the problem being defined as one of classification. Two algorithms, Recursive Partitioning and Regression Trees (RPART) and random forest, are used to predict the quality classification of wines based on the data.

# Analysis

## Data Exploration
After downloading the tidy dataset for each of the white and red wines, they are combined with an added factor for wine colour into a larger dataset names 'wine quality'. We note the length (`r nrow(wine_quality)`) and the features present in the dataset. We can see the structure of the data by printing the first few rows of the data.

```{r data glimpse, echo=FALSE, fig.width=6, message=FALSE, warning=FALSE}
kable(head(wine_quality),
      col.names = gsub("[.]", " ",names(wine_quality)),
      digits = 3) %>%
  kable_styling(latex_options = "scale_down")
```

Next, we take a look at the distributions of the features by plotting histograms of each:

```{r distributions, echo=FALSE, message=FALSE, warning=FALSE}
#observe distributions
wine_quality %>%
  keep(is.numeric) %>%
  pivot_longer(cols = everything()) %>%
  ggplot(aes(value)) +
  facet_wrap(~ name, scales = "free") +
  geom_histogram()
```

We note a few interesting observations:

- Quality is only rated at integers below 3 or above 9  
- Most wines rated either 5 or 6  
- Total sulfur has a bi-modal distribution  
- The density is very uniform across all observations  
- long tails on many of the distributions  

Next, we check for correlations between the features using a heatmap with red being positive and blue being negative.

```{r corr heatmap, echo=FALSE, message=FALSE, warning=FALSE}
#calculate correlations between predictors
correlations <- cor(wine_quality %>% keep(is.numeric))

#plot correlations on heatmap
col<- colorRampPalette(c("blue", "white", "red"))(20) #set heatmap colour palette
heatmap(x = correlations, col = col, symm = TRUE)
```
Alcohol, density, and volatile acid appear most correlated with quality. We also see correlations of density with alcohol and free sulfur dioxide with total sulfur as may be expected. Alcohol is less dense than than the water which makes up most of the remainder of the wine, and free sulfur dioxide is a component of total sulfur dioxide.

Next, to better achieve the goal of the analysis, we group the wine quality ratings. 5 and 6 are grouped into 'med' (very prevalent); 3 and 4 to 'low'; and 7, 8 and 9 into 'high' (both much less prevalent). This allows for better visualization and more practical classification. A wine maker is likely most interested in avoiding low quality product or achieving high quality product.

First we visualize the differences between reds and whites using density plots:

```{r by colour, echo=FALSE, message=FALSE, warning=FALSE}
#Group quality into high, med, and low
wine_quality$quality.lvl <- fct_collapse(as.factor(wine_quality$quality),
                                         low = c("3","4"),
                                         med = c("5","6"),
                                         high = c("7","8","9"))

#Plot density plots by colour across predictors. We expect colour to be important to classify.
wine_quality %>%
  pivot_longer(cols = 1:12) %>%
  ggplot(aes(value, colour = colour)) +
  facet_wrap(~ name, scales = "free") +
  geom_density()
```

Here we note the reason for the bimodal total sulfur distribution, with whites containing higher levels in general. Similarly, reds contain more volatile acidity. What is not observed is a marked difference in quality through this dataset.

```{r by quality, echo=FALSE, message=FALSE, warning=FALSE}
#Plot density plots by assigned quality level across predictors for red wine
wine_quality %>%
  select(-quality) %>%
  filter(colour == "red") %>%
  pivot_longer(cols = 1:11) %>%
  ggplot(aes(value, colour = quality.lvl)) +
  facet_wrap(~ name, scales = "free") +
  geom_density() +
  ggtitle("Red Wines")

#Plot density plots by assigned quality level across predictors for white wine
wine_quality %>%
  select(-quality) %>%
  filter(colour == "white") %>%
  pivot_longer(cols = 1:11) %>%
  ggplot(aes(value, colour = quality.lvl)) +
  facet_wrap(~ name, scales = "free") +
  geom_density() +
  ggtitle("White Wines")
```

Using these plots we see the same features predicting quality as found using a general correlation. Higher alcohol, lower density, and lower volatile acidity wines appear to be rated more highly.
```{r partitioning, message=FALSE, warning=FALSE, include=FALSE}
##Train models
#repeatable randomness
set.seed(1, sample.kind = "Rounding")
#create data partition index to split 20% of the wine quality set into a test set and 80% into a training set
train_index <- createDataPartition(y = wine_quality$quality.lvl,
                                   p = 0.8,
                                   list = FALSE)

#create partitioned data sets using index
train_set <- wine_quality[train_index,] %>% select(-quality) #remove quality as a predictor
test_set <- wine_quality[-train_index,] %>% select(-quality) #remove quality as a predictor
```

## Modeling

Firstly, the training dataset 'wine quality' is partitioned into a 'train' set and a 'test' set for various models to be trained while avoiding overfitting. The caret function 'createDataPartition' is used to stratify the data by quality level to maintain the prevalence of high and low quality wines. 80% of the data, or `r nrow(train_set)` randomly selected ratings make up the training set and the remaining `r nrow(test_set)` ratings are used for model testing. 80% is used for training to avoid over fitting with the moderate number of predictors.

The first classification algorithm used is RPART. The benefit of this algorithm is the easy interpretability although it is rarely the most accurate. The 'caret' package is used alongside the 'rpart' package to train the model. the complexity parameter, that is the minimum improvement in model accuracy to keep a new branch of the decision tree, is Kappa. This metric is better for the 'wine quality' data where high and low quality wines are rare. The metric compares the model accuracy to that of a random selector. The resulting classification model is shown here:

```{r decision tree, echo=FALSE, message=FALSE, warning=FALSE}
#fit decision tree algorithm. Using Kappa because of the low prevalence of high and low quality wines
fit_dt <- train(quality.lvl ~ .,
                method = "rpart",
                metric = "Kappa",
                data = train_set)

#plot the decision tree
plot(fit_dt$finalModel, margin = 0.1)
text(fit_dt$finalModel, cex = 0.65)
```

Alcohol, which we've seen is most strongly correlated to wine quality, is unsurprisingly the driver of the model. There are issues with the model, however, as no low quality wines are ever classified. This limits the usefulness of the model for any winemaker interested in avoiding low quality wine. To overcome this, we weight observations of low quality wines higher in the recursive partitioning process and check the model output:

```{r weighted decision tree, echo=FALSE, message=FALSE, warning=FALSE}
#increasing weights of low quality wines based on their prevalence
positiveWeight = 1.0 / (nrow(subset(train_set, quality.lvl == "low")) / nrow(train_set))
negativeWeight = 1.0 / (nrow(subset(train_set, quality.lvl %in% c("med", "high"))) / nrow(train_set))

#create weighting index
weights_dt <- ifelse(train_set$quality.lvl == "low", positiveWeight, negativeWeight)

#create weighted decision tree model with many complexity parameters
fit_dt_weighted <- train(quality.lvl ~ .,
                         method = "rpart",
                         metric = "Kappa",
                         tuneGrid = data.frame(cp = seq(0.02, 0.05, len = 10)),
                         weights = weights_dt,
                         data = train_set)

#plot decision tree created with weighted observations
plot(fit_dt_weighted$finalModel, margin = 0.1)
text(fit_dt_weighted$finalModel, cex = 0.65)
```

This model would be more useful for a winemaker looking to avoid poor product, but not as useful for one interested in a premium product. We can see the accuracy of the model across a grid of tuning parameters, in this case the complexity parameter 'cp'. We see an increase in Kappa, which is interpreted as only a small advantage over a random selection, increasing as 'cp' is lowered. This is likely due to overfitting the training data, a weakness of the RPART algorithm. The F1 score of the model is also included. F1 is chosen as it balances selectivity with sensitivity.

```{r weighted decision tree evaluation, echo=FALSE, message=FALSE, warning=FALSE}

#print results of cross validation
ggplot(fit_dt_weighted)

##Evaluate on test set
#compute modeled predictions
pred_dt_weighted <- predict(fit_dt_weighted,test_set)

#print confusion matrix for model evaluation
cm_dt_weighted <- confusionMatrix(pred_dt_weighted, test_set$quality.lvl)
kable(cm_dt_weighted[["byClass"]][ , "F1"], col.names = c(NULL, "F1 Score")) %>%
  kable_styling(position = "center")
```

Model performance can certainly be improved with other, more flexible, algorithms. Random forest is run next to classify both high and low quality wines with a higher F1 score. We use the same Kappa metric and reduce the number of trees to 100 after an initial run with the default 500 trees that shows a plateau in the error metrics, to reduce computation time.

```{r random forest ntrees, echo=FALSE, message=FALSE, warning=FALSE}
##Use random forest to overcome the inflexibility of a single tree
#try all possible number of predictors for tuning
tunegrid <- expand.grid(mtry=c(1:10))

#set number of trees to reduce computation time by 80%
fit_rf <- train(quality.lvl ~ .,
                method = "rf",
                metric = "Kappa",
                ntree = 100,
                tuneGrid = tunegrid,
                data = train_set)

#plot ntrees plateau
plot(fit_rf$finalModel)
```


The number of predictors selected for each decision tree in the random forest can be a useful tuning parameter for the algorithm. In this case we see little improvement beyond 3 predictors per tree.
```{r random forest mtry, echo=FALSE, message=FALSE, warning=FALSE}
#plot the tuning of mtry parameter
ggplot(fit_rf)
```

```{r random forest mtry, echo=FALSE, message=FALSE, warning=FALSE}
##Evaluate on test set
#compute modeled predictions
pred_rf <- predict(fit_rf,test_set)

#print confusion matrix for model evaluation
cm_rf_weighted <- confusionMatrix(pred_rf, test_set$quality.lvl)
cm_rf_weighted[["byClass"]][ , "F1"]

#plot variable importance of predictors
ggplot(varImp(fit_rf))

#here we see the most correlated factors having the largest importance within the model

```

# Results

# Conclusions