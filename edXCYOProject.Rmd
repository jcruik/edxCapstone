---
title: "edX Vinho Verde Quality Prediction Project"
author: "James Cruikshanks"
date: "7/27/2021"
output: pdf_document
---

```{r setup, include=FALSE}
###Vinho Verde Quality Predictor
##Load required packages
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(caret)) install.packages("caret")
if(!require(rpart)) install.packages("rpart")
if(!require(randomForest)) install.packages("randomForest")
if(!require(knitr)) install.packages("knitr")
if(!require(kableExtra)) install.packages("kableExtra")

library(tidyverse)
library(caret)
library(rpart)
library(knitr)
library(kableExtra)

##Wrangle wine quality data
##data located here: http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip

#download zip file
dl <- tempfile()
download.file("http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip", dl)

#read csv files
reds <- read.csv(unzip(dl,"winequality/winequality-red.csv"), sep = ";")
whites <- read.csv(unzip(dl,"winequality/winequality-white.csv"), sep = ";")

#add categorical data
reds <- reds %>% mutate(colour = as.factor("red"))
whites <- whites %>% mutate(colour = as.factor("white"))

#merge data
wine_quality <- bind_rows(reds, whites)

#remove temp files
remove(dl, reds, whites)

#set the number of digits for rounding
options(digits = 5)

```
# Introduction

Using a public data set and R scripts, this project attempts to create a model which would be useful to identify wine quality with a suite of chemical analyses. The data set is available at the following URL: http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip. Exploratory data analysis reveals some useful insights about a few of the predictors and the subjective quality ratings themselves. The goal of the project is refined based on these insights, with the problem being defined as one of classification. Two algorithms, Recursive Partitioning and Regression Trees (RPART) and random forest, are used to predict the quality classification of wines based on the data.

# Analysis

## Data Exploration
After downloading the tidy data set for each of the white and red wines, they are combined with an added factor for wine colour into a larger data set names 'wine quality'. We note the length (`r nrow(wine_quality)`) and the features present in the data set. We can see the structure of the data by printing the first few rows of the data.

```{r data glimpse, echo=FALSE, fig.width=6, message=FALSE, warning=FALSE}
kable(head(wine_quality),
      col.names = gsub("[.]", " ",names(wine_quality)),
      digits = 3) %>%
  kable_styling(latex_options = "scale_down")
```

Next, we take a look at the distributions of the features by plotting histograms of each:

```{r distributions, echo=FALSE, message=FALSE, warning=FALSE}
#observe distributions
wine_quality %>%
  keep(is.numeric) %>%
  pivot_longer(cols = everything()) %>%
  ggplot(aes(value)) +
  facet_wrap(~ name, scales = "free") +
  geom_histogram()
```

We note a few interesting observations:

- Quality is only rated at integers below 3 or above 9  
- Most wines rated either 5 or 6  
- Total sulfur has a bi-modal distribution  
- The density is very uniform across all observations  
- long tails on many of the distributions  

Next, we check for correlations between the features using a heatmap with red being positive and blue being negative.

```{r corr heatmap, echo=FALSE, message=FALSE, warning=FALSE}
#calculate correlations between predictors
correlations <- cor(wine_quality %>% keep(is.numeric))

#plot correlations on heatmap
col<- colorRampPalette(c("blue", "white", "red"))(20) #set heatmap colour palette
heatmap(x = correlations, col = col, symm = TRUE)
```
Alcohol, density, and volatile acid appear most correlated with quality. We also see correlations of density with alcohol and free sulfur dioxide with total sulfur as may be expected. Alcohol is less dense than than the water which makes up most of the remainder of the wine, and free sulfur dioxide is a component of total sulfur dioxide.

Next, to better achieve the goal of the analysis, we group the wine quality ratings. 5 and 6 are grouped into 'med' (very prevalent); 3 and 4 to 'low'; and 7, 8 and 9 into 'high' (both much less prevalent). This allows for better visualization and more practical classification. A wine maker is likely most interested in avoiding low quality product or achieving high quality product.

First we visualize the differences between reds and whites using density plots:

```{r by colour, echo=FALSE, message=FALSE, warning=FALSE}
#Group quality into high, med, and low
wine_quality$quality.lvl <- fct_collapse(as.factor(wine_quality$quality),
                                         low = c("3","4"),
                                         med = c("5","6"),
                                         high = c("7","8","9"))

#Plot density plots by colour across predictors. We expect colour to be important to classify.
wine_quality %>%
  pivot_longer(cols = 1:12) %>%
  ggplot(aes(value, colour = colour)) +
  facet_wrap(~ name, scales = "free") +
  geom_density()
```

Here we note the reason for the bimodal total sulfur distribution, with whites containing higher levels in general. Similarly, reds contain more volatile acidity. What is not observed is a marked difference in quality through this data set.

```{r by quality, echo=FALSE, message=FALSE, warning=FALSE}
#Plot density plots by assigned quality level across predictors for red wine
wine_quality %>%
  select(-quality) %>%
  filter(colour == "red") %>%
  pivot_longer(cols = 1:11) %>%
  ggplot(aes(value, colour = quality.lvl)) +
  facet_wrap(~ name, scales = "free") +
  geom_density() +
  ggtitle("Red Wines")

#Plot density plots by assigned quality level across predictors for white wine
wine_quality %>%
  select(-quality) %>%
  filter(colour == "white") %>%
  pivot_longer(cols = 1:11) %>%
  ggplot(aes(value, colour = quality.lvl)) +
  facet_wrap(~ name, scales = "free") +
  geom_density() +
  ggtitle("White Wines")
```

Using these plots we see the same features predicting quality as found using a general correlation. Higher alcohol, lower density, and lower volatile acidity wines appear to be rated more highly.
```{r partitioning, message=FALSE, warning=FALSE, include=FALSE}
##Train models
#repeatable randomness
set.seed(1, sample.kind = "Rounding")
#create data partition index to split 20% of the wine quality set into a test set and 80% into a training set
train_index <- createDataPartition(y = wine_quality$quality.lvl,
                                   p = 0.8,
                                   list = FALSE)

#create partitioned data sets using index
train_set <- wine_quality[train_index,] %>% select(-quality) #remove quality as a predictor
test_set <- wine_quality[-train_index,] %>% select(-quality) #remove quality as a predictor
```

## Modeling

Firstly, the training data set 'wine quality' is partitioned into a 'train' set and a 'test' set for various models to be trained while avoiding overfitting. The caret function 'createDataPartition' is used to stratify the data by quality level to maintain the prevalence of high and low quality wines. 80% of the data, or `r nrow(train_set)` randomly selected ratings make up the training set and the remaining `r nrow(test_set)` ratings are used for model testing. 80% is used for training to avoid over fitting with the moderate number of predictors.

The first classification algorithm used is RPART. The benefit of this algorithm is the easy interpretability although it is rarely the most accurate. The 'caret' package is used alongside the 'rpart' package to train the model. the complexity parameter, that is the minimum improvement in model accuracy to keep a new branch of the decision tree, is Kappa. This metric is better for the 'wine quality' data where high and low quality wines are rare. The metric compares the model accuracy to that of a random selector. The resulting classification model is shown here:

```{r decision tree, echo=FALSE, message=FALSE, warning=FALSE}
#fit decision tree algorithm. Using Kappa because of the low prevalence of high and low quality wines
fit_dt <- train(quality.lvl ~ .,
                method = "rpart",
                metric = "Kappa",
                data = train_set)

#plot the decision tree
plot(fit_dt$finalModel, margin = 0.1)
text(fit_dt$finalModel, cex = 0.65)
```

Alcohol, which we've seen is most strongly correlated to wine quality, is unsurprisingly the driver of the model. There are issues with the model, however, as no low quality wines are ever classified. This limits the usefulness of the model for any winemaker interested in avoiding low quality wine. To overcome this, we weight observations of low quality wines higher in the recursive partitioning process and check the model output:

```{r weighted decision tree, echo=FALSE, message=FALSE, warning=FALSE}
#increasing weights of low quality wines based on their prevalence
positiveWeight = 1.0 / (nrow(subset(train_set, quality.lvl == "low")) / nrow(train_set))
negativeWeight = 1.0 / (nrow(subset(train_set, quality.lvl %in% c("med", "high"))) / nrow(train_set))

#create weighting index
weights_dt <- ifelse(train_set$quality.lvl == "low", positiveWeight, negativeWeight)

#create weighted decision tree model with many complexity parameters
fit_dt_weighted <- train(quality.lvl ~ .,
                         method = "rpart",
                         metric = "Kappa",
                         tuneGrid = data.frame(cp = seq(0.02, 0.05, len = 10)),
                         weights = weights_dt,
                         data = train_set)

#plot decision tree created with weighted observations
plot(fit_dt_weighted$finalModel, margin = 0.1)
text(fit_dt_weighted$finalModel, cex = 0.65)
```

This model would be more useful for a winemaker looking to avoid poor product, but not as useful for one interested in a premium product. We can see the accuracy of the model across a grid of tuning parameters, in this case the complexity parameter 'cp'. We see an increase in Kappa, which is interpreted as only a small advantage over a random selection, increasing as 'cp' is lowered. This is likely due to overfitting the training data, a weakness of the RPART algorithm. The F1 score of the model is also included. F1 is chosen as it balances selectivity with sensitivity.

```{r weighted decision tree evaluation, echo=FALSE, message=FALSE, warning=FALSE}

#print results of cross validation
ggplot(fit_dt_weighted)

##Evaluate on test set
#compute modeled predictions
pred_dt_weighted <- predict(fit_dt_weighted,test_set)

#print confusion matrix for model evaluation
cm_dt_weighted <- confusionMatrix(pred_dt_weighted, test_set$quality.lvl)
kable(cm_dt_weighted[["byClass"]][ , "F1"], col.names = c(NULL, "F1 Score")) %>%
  kable_styling(position = "center")
```

Model performance can certainly be improved with other, more flexible, algorithms. Random forest is run next to classify both high and low quality wines with a higher F1 score. We use the same Kappa metric and reduce the number of trees to 100 after an initial run with the default 500 trees that shows a plateau in the error metrics, to reduce computation time.

```{r random forest ntrees, echo=FALSE, message=FALSE, warning=FALSE}
##Use random forest to overcome the inflexibility of a single tree
#try all possible number of predictors for tuning
tunegrid <- expand.grid(mtry=c(1:10))

#train randomforest model across 10 values of mtry
fit_rf <- train(quality.lvl ~ .,
                method = "rf",
                metric = "Kappa",
                tuneGrid = tunegrid,
                data = train_set)

#plot ntrees plateau
plot(fit_rf$finalModel)
```

The number of predictors selected for each decision tree in the random forest can be a useful tuning parameter for the algorithm. In this case we see little improvement beyond 3 predictors per tree but slightly higher accuracy with 8, which is selected for use in the final model.
```{r random forest mtry, echo=FALSE, message=FALSE, warning=FALSE}
#plot the tuning of mtry parameter
ggplot(fit_rf)
```
Next we plot the variable importance of each predictor to see which are most important for modeling, below. We notice the most important predictors are those which were most highly correlated with quality in the original data: alcohol, density, and volatile acidity. A winemaker might cut analysis costs by forgoing lower importance predictors.
```{r random forest varImp, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}
#plot the variable importance of predictors
ggplot(varImp(fit_rf))
```

# Results

Using the random forest model, we predict the quality level of the wines observed in the test set and print the confusion matrix and F1 scores.
```{r random forest eval, echo=FALSE, message=FALSE, warning=FALSE}
##Evaluate on test set
#compute modeled predictions
pred_rf <- predict(fit_rf,test_set)

#print confusion matrix for model evaluation
cm_rf <- confusionMatrix(pred_rf, test_set$quality.lvl)
cm_rf$table
kable(cm_rf[["byClass"]][ , "F1"], col.names = c(NULL, "F1 Score")) %>%
  kable_styling(position = "center")
```

Here we see that the model is much improved from the RPART weighted decision tree, with high quality wines predicted, nearly double the F1 score on low quality wines, and over 20% higher F1 score for medium quality wines. This reinforces the model performance seen during training with Kappa values of 0.48, indicating that the model was close to 50% better than chance at identifying the rare high and low quality wines. High quality wines are more easily identified than lower quality wines with the final model, and the model would be useful in practice.

# Conclusions

After downloading a data set of wine ratings, a number of statistical insights were gathered to inform a modeling approach. Examining the distribution of quality ratings it is clear that the project goals were suited to a classification model. A decision tree model was inflexible yet helpful to interpret the decision making taking place. A random forest model improved upon the decision tree model, providing flexibility at the cost of interpretability. In the end a model was developed which could be used by a winemaker to automatically estimate quality based mostly upon alocohol content, density, and volatile acidity. The model was developed with both sensitivity and selectivity as evaluation metrics. It can identify low quality wines with an F1 score of 0.28, medium quality wines with an F1 score of 0.91, and high quality wines with an F1 score of 0.67. The model could be improved by inclusion of many more observations, and perhaps in consultation with subject matter experts to determine which chemical analyses would influence taste beyond those included in this data set. Other classification models beyond the scope of the course may also be considered, such as neural networks.